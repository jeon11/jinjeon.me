<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>research | Jin Jeon</title>
    <link>https://jinjeon.me/tags/research/</link>
      <atom:link href="https://jinjeon.me/tags/research/index.xml" rel="self" type="application/rss+xml" />
    <description>research</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>¬© 2021 developed by Jin Jeon with HTML/CSS/Markdown and ‚ù§Ô∏è </copyright><lastBuildDate>Thu, 10 Dec 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jinjeon.me/img/icon.png</url>
      <title>research</title>
      <link>https://jinjeon.me/tags/research/</link>
    </image>
    
    <item>
      <title>Coffitok</title>
      <link>https://jinjeon.me/project/coffitok/</link>
      <pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/project/coffitok/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Alaska Airlines (Company sponsored summer project/NDA)</title>
      <link>https://jinjeon.me/project/alaska-airlines/</link>
      <pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/project/alaska-airlines/</guid>
      <description>

&lt;style&gt;
.introduction {
  column-count: 2;
}
&lt;/style&gt;

&lt;p&gt;&lt;body style=&#34;font-family:Arial; font-size: 12pt&#34;&gt;
&lt;div class=&#34;introduction&#34;&gt;
&lt;b&gt;My Role:&lt;/b&gt;
&lt;br&gt;&lt;small&gt;UX researcher in a 4-person team of researchers and designers&lt;/small&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Methods:&lt;/b&gt;
&lt;br&gt;&lt;small&gt;generative research, competitive analysis, remote qualitative interview, journey map, affinity diagram&lt;/small&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Timeline: &lt;/b&gt;
&lt;br&gt;&lt;small&gt;June 2020 - Oct 2020 (~4 months)&lt;/small&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Stakeholders:&lt;/b&gt;
&lt;br&gt;&lt;small&gt;Research manager, product designers, &lt;br&gt;brand manager, eCommerce team&lt;/small&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;To help Alaska Airlines flexibly adapt to the COVID-19 pandemic and improve its upsell strategies, we conducted user research to understand users&amp;rsquo; behaviors, values, and motivations at different stages of their flight travel experiences. We studied Alaska Airlines and five other major airlines operating in the US to conduct competitive analysis and pair insights from user experience benchmarking.&lt;/p&gt;

&lt;h2 id=&#34;impact&#34;&gt;Impact&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Presented four major recommendations to research managers, product and eCommerce teams.&lt;/li&gt;
&lt;li&gt;Research findings matched with the ongoing internal research, suggesting its validity.&lt;/li&gt;
&lt;li&gt;Provided new insights to improve users&amp;rsquo; overall experiences by adapting to the pandemic world.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;research-question&#34;&gt;Research Question&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;p style=&#34;font-size: 16pt&#34;&gt;&lt;mark&gt;&lt;em&gt;&amp;ldquo;What are the motivations for upgrading throughout the booking and overall flight experience with Alaska and its competitors? Additionally, has the current pandemic affected this experience?&amp;rdquo;&lt;/em&gt;&lt;/mark&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;project-timeline&#34;&gt;Project Timeline&lt;/h2&gt;

&lt;!-- ![Project Timeline](./timeline.svg) --&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;timeline.svg&#34; data-caption=&#34;Our project spanned from late June to October. We initiated our study with reviewing company&amp;rsquo;s past research, examining the different competitors and case studies. We then proceeded with running qualitative interviews on UserTesting.com to get to the hearty meat of this research&#34;&gt;
&lt;img src=&#34;timeline.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Our project spanned from late June to October. We initiated our study with reviewing company&amp;rsquo;s past research, examining the different competitors and case studies. We then proceeded with running qualitative interviews on UserTesting.com to get to the hearty meat of this research
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;user-research&#34;&gt;User Research&lt;/h2&gt;

&lt;p&gt;Please note that below are &lt;strong&gt;&lt;em&gt;summarized insights&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;challenges&lt;/em&gt;&lt;/strong&gt; our team had during the user research process.&lt;/p&gt;

&lt;h3 id=&#34;preliminary-competitive-analysis&#34;&gt;Preliminary &amp;amp; Competitive Analysis&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt;&lt;br&gt;
To first better understand the competitive landscape of the airline industries, we examined the websites of the six airlines to visualize the user flow of booking a flight.&lt;/p&gt;

&lt;p&gt;üí° &lt;strong&gt;Key/fun Fact:&lt;/strong&gt;&lt;br&gt;
Despite the industry standard of generalizing the classification of seat types into economy, business, and first class, we noticed that each airline had different ways of classifying, naming, and promoting the different fare classes. We searched for areas that could be confusing and be improved for the users.&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;fareclass.svg&#34; data-caption=&#34;Each airline had its own ways of classifying and naming the seats. Even though the perks that came along with each fare type were quite consistent throughout, low-cost airline, such as Southwest, had a uniquely different seating plan.&#34;&gt;
&lt;img src=&#34;fareclass.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;Each airline had its own ways of classifying and naming the seats. Even though the perks that came along with each fare type were quite consistent throughout, low-cost airline, such as Southwest, had a uniquely different seating plan.&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h4 id=&#34;insights&#34;&gt;Insights:&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Alaska Airlines&lt;/strong&gt;&amp;rsquo; fare types were straightforward and transparent. The seat names are in consistent ascending order: &lt;br&gt;i.e. saver ‚Üí economy ‚Üí premium ‚Üí first class.&lt;/li&gt;
&lt;li&gt;Fare types and their associated perks can become very unclear:&lt;br&gt;
e.g. &lt;strong&gt;JetBlue&lt;/strong&gt;&amp;rsquo;s first class name is &amp;ldquo;Mint&amp;rdquo; which has no association with Blue.&lt;br&gt;
e.g. &lt;strong&gt;SouthWest&lt;/strong&gt;&amp;rsquo;s distinction between basic economy and economy is vague.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;United&lt;/strong&gt; had the most visually busy interface and complex fare types, leading to a poor booking experience.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;qualitative-interview&#34;&gt;Qualitative Interview&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt;&lt;br&gt;
To understand users&amp;rsquo;:
&lt;ol&gt;
  &lt;li&gt;General flight behavior&lt;/li&gt;
  &lt;li&gt;Top values&lt;br&gt;&lt;/li&gt;
  &lt;li&gt;Pain points&lt;br&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Methods:&lt;/strong&gt;&lt;br&gt;
&lt;ol&gt;
&lt;li&gt;&lt;b&gt;Remote Qualitative Interview: &lt;/b&gt;&lt;br&gt;
We conducted a total of 30 interviews (5 participants from 6 different airlines) remotely over UserTesting.com and Zoom. We probed for their general flying behaviors and preferences, and narrowed down to their most recent flight experience (considering both pre-COVID &amp;amp; post-COVID).&lt;/li&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;demographics.svg&#34; data-caption=&#34;We accounted for various factors, including age, gender, income range, and travel behaviors, during our interview to capture the holistic view of participants&amp;rsquo; travel experiences.&#34;&gt;
&lt;img src=&#34;demographics.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;We accounted for various factors, including age, gender, income range, and travel behaviors, during our interview to capture the holistic view of participants&amp;rsquo; travel experiences.&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;&lt;li&gt;&lt;b&gt;Interactive Journey Maps:&lt;/b&gt;&lt;br&gt;
We incorporated an &lt;strong&gt;interactive journey map&lt;/strong&gt; session in each interview to have participants walkthrough their most recent experience and capture their moment-to-moment emotions and actions.&lt;/li&gt;&lt;/p&gt;

&lt;p&gt;To capture their moment-to-moment emotions and actions, we divided the entire flight experience into 5 phases:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;booking the flight ticket&lt;/strong&gt; (e.g. web vs. mobile vs. phone)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;before 24 hours of travel&lt;/strong&gt; (includes preparation and traveling to the airport)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;being at the airport&lt;/strong&gt; (checking-in, luggage, security checks, and so on)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;in-flight&lt;/strong&gt; (seat space, perks, food &amp;amp; beverage, etc)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;arrival&lt;/strong&gt; (post travel experience)&lt;/li&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;journeymapping.svg&#34; data-caption=&#34;A simplified abstract example of the interactive journey map: Participants can vertically toggle each action item (as shown in the red arrows) based on their overall experience of that particular event (Good to Poor).&#34;&gt;
&lt;img src=&#34;journeymapping.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;A simplified abstract example of the interactive journey map: Participants can vertically toggle each action item (as shown in the red arrows) based on their overall experience of that particular event (Good to Poor).&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;/ol&gt;&lt;/p&gt;

&lt;h2 id=&#34;thematic-analysis&#34;&gt;Thematic Analysis&lt;/h2&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;themes.svg&#34; data-caption=&#34;We explored multi-facets of the travel experience to search for emerging themes from the qualitative data we collected from interviews and journey maps.&#34;&gt;
&lt;img src=&#34;themes.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;We explored multi-facets of the travel experience to search for emerging themes from the qualitative data we collected from interviews and journey maps.&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;affinitymap.svg&#34; data-caption=&#34;Overview of our affinity map. We inductively searched for overarching themes by&amp;hellip;Participant journey map ‚Üí airline journey map ‚Üí all airline journey map. From each participant&amp;rsquo;s journey map, we combined them to characterize the overall experience of each airline. We then combined all airlines to identify any patterns.&#34;&gt;
&lt;img src=&#34;affinitymap.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;Overview of our affinity map. We inductively searched for overarching themes by&amp;hellip;&lt;br&gt;Participant journey map ‚Üí airline journey map ‚Üí all airline journey map. &lt;br&gt;From each participant&amp;rsquo;s journey map, we combined them to characterize the overall experience of each airline. We then combined all airlines to identify any patterns.&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;key-insights-results&#34;&gt;Key Insights &amp;amp; Results&lt;/h2&gt;

&lt;p&gt;Please note that below are &lt;strong&gt;&lt;em&gt;partial results&lt;/em&gt;&lt;/strong&gt; due to NDA.&lt;/p&gt;

&lt;h3 id=&#34;personas-highlights&#34;&gt;Personas/Highlights&lt;/h3&gt;

&lt;p&gt;We developed three prototypical personas (&lt;strong&gt;we intentionally used the term &amp;ldquo;highlight&amp;rdquo; instead of &amp;ldquo;persona&amp;rdquo; because they were modeled after participants that stood out with clear preference of values and motivations&lt;/strong&gt;). We introduced the demographic information, a hypothetical trip destination, quote from the interview, means used to book and upgrade the seat. We also identified top values, pain points, and motivations for upgrading a seat. Only 1 of the 3 is shown here.&lt;/p&gt;

&lt;!-- 












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;persona1.svg&#34; data-caption=&#34;This first type of personas is characterized by how upgrading a seat is mandatory due to his large body size. With his tall height and broad shoulders, upgrading a seat is a necessity.&#34;&gt;
&lt;img src=&#34;persona1.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;This first type of personas is characterized by how upgrading a seat is mandatory due to his large body size. With his tall height and broad shoulders, upgrading a seat is a necessity.&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;
 --&gt;

&lt;!-- 












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;persona2.svg&#34; data-caption=&#34;The second person is characterized by how traveling in the pandemic era is worst not just because of the safety concerns, but also due to the lack of services. Another unique perspective is the consideration for how family members can buy tickets for other family members.&#34;&gt;
&lt;img src=&#34;persona2.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;The second person is characterized by how traveling in the pandemic era is worst not just because of the safety concerns, but also due to the lack of services. Another unique perspective is the consideration for how family members can buy tickets for other family members.&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;
 --&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;persona3.svg&#34; data-caption=&#34;This person is characterized as a bargain hunter, constantly looking for deals and offers. The person is unique in that he is tech savvy and even conscious about which aircraft type he would be flying in.&#34;&gt;
&lt;img src=&#34;persona3.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;This person is characterized as a &lt;i&gt;bargain hunter&lt;/i&gt;, constantly looking for deals and offers. The person is unique in that he is tech savvy and even conscious about which aircraft type he would be flying in.&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h3 id=&#34;characterizing-the-travel-experience&#34;&gt;Characterizing the Travel Experience&lt;/h3&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;journeymap.svg&#34; data-caption=&#34;An overall experience of Airline X: We visualized a typical journey map, capturing the different motivations for upgrading a seat at each stage of travel. We identified values, emotions, and quotes.&#34;&gt;
&lt;img src=&#34;journeymap.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;An overall experience of Airline X:&lt;/b&gt; &lt;br&gt;We visualized a typical journey map, capturing the different motivations for upgrading a seat at each stage of travel. We identified values, emotions, and quotes.
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;p&gt;We then devised step-by-step recommendations for each travel stage (NDA).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;recommendations&#34;&gt;Recommendations&lt;/h2&gt;

&lt;p&gt;Please note this part is NDA sensitive. Based on key insights and results we synthesized from the data, we came up with four major recommendations.













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;recommendations.svg&#34; data-caption=&#34;The four high level recommendations&#34;&gt;
&lt;img src=&#34;recommendations.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;The four high level recommendations&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;üí° &lt;strong&gt;Key/Fun Fact:&lt;/strong&gt;&lt;br&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;TRANSPARENCY MATTERS&lt;/strong&gt;: it is a critical factor in the overall experience especially due to COVID. Users desire clear communication on what services and ancillaries to expect when flying during this pandemic era.&lt;/li&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Quantitative metrics, such as &lt;strong&gt;time to complete a booking&lt;/strong&gt;, are &lt;strong&gt;less important&lt;/strong&gt; than &lt;strong&gt;transparency&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Transparency translates to expectations. When expectations are not met, the overall experience worsens.&lt;/li&gt;
&lt;li&gt;Clear communication on what each seat upgrade entails can entice users. &lt;br&gt;e.g. &lt;strong&gt;&amp;ldquo;upgrading a seat will get you a 7-inch wider leg room&amp;rdquo;&lt;/strong&gt;.
&lt;!-- &lt;li&gt;**Users don&#39;t mind receiving few more notifications** for clarifying and communicating the travel information (especially if contains deals). &lt;/li&gt; --&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;design-recommendations&#34;&gt;Design Recommendations&lt;/h3&gt;

&lt;p&gt;Based on the four recommendations, we additionally modified some of the website elements to convey more transparency.&lt;/p&gt;

&lt;h4 id=&#34;1-show-what-services-are-suspended&#34;&gt;1. Show what services are suspended&lt;/h4&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;design_rec1.svg&#34; data-caption=&#34;Click to see in large view/ We added a devoted section that clearly communicates what services are currently suspended especially due to COVID (e.g. in-flight food &amp;amp; beverages). When a user is expecting quality in-flight service but does not receive it, the experience cannot be reverted&#34;&gt;
&lt;img src=&#34;design_rec1.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;strong&gt;Click to see in large view&lt;/strong&gt;/ We added a devoted section that clearly communicates what services are currently suspended especially due to COVID (e.g. in-flight food &amp;amp; beverages). When a user is expecting quality in-flight service but does not receive it, the experience cannot be reverted
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h4 id=&#34;2-clearly-communicate-the-perks-of-upgrading&#34;&gt;2. Clearly communicate the perks of upgrading&lt;/h4&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;design_rec2.svg&#34; data-caption=&#34;Click to see in large view/ Communicating what an upgraded seat entails provide transparency and facilitates the upgrading decision.&#34;&gt;
&lt;img src=&#34;design_rec2.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;strong&gt;Click to see in large view&lt;/strong&gt;/ Communicating what an upgraded seat entails provide transparency and facilitates the upgrading decision.
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;limitations-lessons-learned&#34;&gt;Limitations &amp;amp; Lessons Learned&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The participants were not racially diverse as recruitment of participants were automatically done via UserTesting.com.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Majority of participants&amp;rsquo; recent travels occurred 6 months ago, in which they may have distorted memory of their travel experiences.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In a qualitative research, it&amp;rsquo;s more about finding about the big buckets &amp;amp; themes unlike a quant research. &lt;br&gt;
When presenting the different demographic groups, it can be as easy as describing &amp;ldquo;we examined a wide income group&amp;rdquo; instead of graphing out all the different income groups. If all the demographic information was graphically presented, it can convey the different stakeholders, esp. data scientists, that the results and insights will be quant focused when the research is actually qualitative.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;ending.png&#34; data-caption=&#34;With that, I end with a fun quote from one of our participants üòÑ&#34;&gt;
&lt;img src=&#34;ending.png&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;With that, I end with a fun quote from one of our participants&lt;/b&gt; üòÑ
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h2 id=&#34;back-to-top&#34;&gt;&lt;a href=&#34;#&#34;&gt;Back to top ^&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Navigating Cancer (NDA)</title>
      <link>https://jinjeon.me/project/navigating-cancer/</link>
      <pubDate>Fri, 31 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/project/navigating-cancer/</guid>
      <description>

&lt;style&gt;
.introduction {
  column-count: 2;
}
&lt;/style&gt;

&lt;p&gt;&lt;body style=&#34;font-family:Arial; font-size: 12pt&#34;&gt;
&lt;div class=&#34;introduction&#34;&gt;
&lt;b&gt;My Role:&lt;/b&gt;
&lt;br&gt;&lt;small&gt;UX researcher in a 4-person team of researchers and designers&lt;/small&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Methods:&lt;/b&gt;
&lt;br&gt;&lt;small&gt;survey, interview, affinity diagram, prototyping, heuristic evaluation, usability testing&lt;/small&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Timeline: &lt;/b&gt;
&lt;br&gt;&lt;small&gt;Jul 2020 - Sep 2020 (~3 months)&lt;/small&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Stakeholders:&lt;/b&gt;
&lt;br&gt;&lt;small&gt;product manager, senior designer, clinicians, patients&lt;/small&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;To improve patients&amp;rsquo; experiences with symptom management and engagement with the health tracker, the team conducted &lt;strong&gt;user research to identify needs&lt;/strong&gt;, &lt;strong&gt;concept-tested prototypes&lt;/strong&gt;, and &lt;strong&gt;delivered a high-fidelity prototype&lt;/strong&gt; to the leaders and multiple stakeholders.
&lt;br&gt;&lt;strong&gt;+ With COVID-19&lt;/strong&gt;, the team was working remotely as an international, cross-functional team with each of us in different time zones. I was also flying around being in the US and my hometown Korea, making the project more dynamic!&lt;/p&gt;

&lt;h2 id=&#34;impact&#34;&gt;Impact&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Presented research findings and 4 major feature recommendations to leaders and multiple stakeholders.&lt;/li&gt;
&lt;li&gt;Received strong positive feedbacks from the stakeholders, and recommendations aligned with company&amp;rsquo;s future milestones.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;research-question&#34;&gt;Research Question&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;p style=&#34;font-size: 16pt&#34;&gt;&lt;mark&gt;&lt;em&gt;&amp;ldquo;How might we increase patient engagement with health tracker?&amp;rdquo;&lt;/em&gt;&lt;/mark&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;the-design-process&#34;&gt;The Design Process&lt;/h2&gt;

&lt;h3 id=&#34;unfolding-the-research-through-design-framework&#34;&gt;Unfolding the Research through Design Framework&lt;/h3&gt;

&lt;p&gt;Part of our team&amp;rsquo;s mission was to &lt;strong&gt;evangelize the impact of research&lt;/strong&gt; as the company lacked a dedicated research team. We incorporated the &lt;a href=&#34;https://www.designcouncil.org.uk/news-opinion/what-framework-innovation-design-councils-evolved-double-diamond&#34; target=&#34;_blank&#34;&gt;Double Diamond&lt;/a&gt; design framework to help us guide our research focus by better framing the problem and solving the users&amp;rsquo; underlying needs.&lt;/p&gt;

&lt;p&gt;&lt;mark&gt;This case study will unfold along with the different stages of the Double Diamond.&lt;/mark&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-ideal-double-diamond&#34;&gt;The Ideal Double Diamond&lt;/h3&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;doublediamond.png&#34; data-caption=&#34;The ideal double diamond. Design frameworks help organize the design thinking process by helping researchers better frame the problem and focus on identifying and solving the users‚Äô underlying needs.The model, divided into 4 phases (discover, define, develop, and deliver), maps the divergent and convergent stages of the design process.&#34;&gt;
&lt;img src=&#34;doublediamond.png&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;The ideal double diamond. Design frameworks help organize the design thinking process by helping researchers better frame the problem and focus on identifying and solving the users‚Äô underlying needs.&lt;br&gt;The model, divided into 4 phases (discover, define, develop, and deliver), maps the divergent and convergent stages of the design process.&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h4 id=&#34;but-the-reality&#34;&gt;but the Reality&amp;hellip;&lt;/h4&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;reality.png&#34; data-caption=&#34;The deformed double diamond. While the ideal model is a perfectly-shaped two diamonds, the reality of our research journey was a deformed diamond process. We made multiple pivots along the research, which ended up being a valuable process as we gained greater insights to the problem space.&#34;&gt;
&lt;img src=&#34;reality.png&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;The deformed double diamond. While the ideal model is a perfectly-shaped two diamonds, the reality of our research journey was a deformed diamond process. We made multiple pivots along the research, which ended up being a valuable process as we gained greater insights to the problem space.&lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;user-research&#34;&gt;User Research&lt;/h2&gt;

&lt;p&gt;Please note that below are &lt;strong&gt;&lt;em&gt;summarized insights&lt;/em&gt;&lt;/strong&gt; our team had during the user research process.&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;user_research.png&#34; data-caption=&#34;Click to see in large view  Overall high-level research process. We began our research with a general survey. From the insights from the general survey and existing survey results from the company, we conducted interviews with cancer patients and survivors.&#34;&gt;
&lt;img src=&#34;user_research.png&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;strong&gt;Click to see in large view&lt;/strong&gt; &lt;br&gt; &lt;strong&gt;Overall high-level research process.&lt;/strong&gt; We began our research with a general survey. From the insights from the general survey and existing survey results from the company, we conducted interviews with cancer patients and survivors.
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;hr /&gt;

&lt;h3 id=&#34;mark-discover-mark&#34;&gt;&lt;mark&gt;Discover&lt;/mark&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;We initiated our research with a general survey sent out online (n=72) to understand the general space of health care and health trackers. It helped us &lt;strong&gt;identify people&amp;rsquo;s health goals and tracking habits.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;From the general survey results, we devised a remote moderated &lt;strong&gt;interview plan to better understand what it feels like to undergo cancer treatments and how they manage their symptoms.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;From the interview with cancer patients and survivors, &lt;strong&gt;affinity mapping helped us categorize their responses&lt;/strong&gt; into various sections, such as their emotions throughout the oncology journey, how they track and manage their symptoms, interaction with the care team and caregivers, and so on.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;key-insights&#34;&gt;Key Insights&lt;/h4&gt;

&lt;p&gt;Interview with the patients and survivors shed light to clearly understand not just how they manage their symptoms, but &lt;strong&gt;empathize with their adjusted lifestyles and daily challenges.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Through quantitative analysis of the self-reported metrics, I identified that &amp;ldquo;older people&amp;rsquo;s self perception of health level is higher than that of younger people&amp;rdquo;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Cancer oncology treatments were perceived as &lt;strong&gt;long &amp;ldquo;journeys&amp;rdquo;&lt;/strong&gt; even sometimes with no end.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Symptom management varies by each individual, severity, and cancer types.&lt;/strong&gt; As a researcher and designer, another design challenge was how we can deliver a solution that addresses all cancer types and patients.&lt;/li&gt;
&lt;/ul&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;discover.svg&#34; data-caption=&#34;Click to see large view. &#34;&gt;
&lt;img src=&#34;discover.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;Click to see large view. &lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;hr /&gt;

&lt;h3 id=&#34;mark-define-mark&#34;&gt;&lt;mark&gt;Define&lt;/mark&gt;&lt;/h3&gt;

&lt;p&gt;Below are only partial insights synthesized.&lt;br&gt;&lt;/p&gt;

&lt;p&gt;üí° &lt;strong&gt;Key Insight:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Identifying the user needs and listing out the stories in a prioritized order immensely helped the team properly guide to the next steps.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;We synthesized potential features that would address the user needs.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;define.svg&#34; data-caption=&#34;User Stories. These are partial high-level user stories synthesized from the research. &#34;&gt;
&lt;img src=&#34;define.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;User Stories. These are partial high-level user stories synthesized from the research. &lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;hr /&gt;

&lt;h3 id=&#34;mark-develop-mark&#34;&gt;&lt;mark&gt;Develop &lt;/mark&gt;&lt;/h3&gt;

&lt;p&gt;üí° &lt;strong&gt;Key Insights:&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;With my background in data visualization, &lt;strong&gt;I was particularly fascinated in developing visual dashboards and data visualization to help patients track their symptoms.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;One key lesson I learned was: &lt;mark&gt;&lt;strong&gt;Designing should always consider the target audience first.&lt;/strong&gt;&lt;/mark&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Excited to develop data visualization screens, &lt;strong&gt;I initially thought that the more diverse, interactive, and comprehensive graphs are, the better.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Nevertheless, during the expert evaluation and concept-testing, I realized that the screens were simply too busy and users (particularly the old population that are less tech savvy) find the &lt;strong&gt;visuals to be too complicated and less informative.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;develop.svg&#34; data-caption=&#34;Click to see in large view.  Developing prototypes. We began our development with quick sketches using Google&amp;rsquo;s Crazy 8&amp;rsquo;s methodology. We used Figma to develop into a high-fidelity prototypes, which were later concept-tested in the deliver phase &#34;&gt;
&lt;img src=&#34;develop.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;Click to see in large view. &lt;br&gt; Developing prototypes. We began our development with quick sketches using Google&amp;rsquo;s Crazy 8&amp;rsquo;s methodology. We used Figma to develop into a high-fidelity prototypes, which were later concept-tested in the deliver phase &lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h4 id=&#34;concept-testing&#34;&gt;Concept-testing&lt;/h4&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;concept_test.svg&#34; data-caption=&#34;We conducted concept-testing with 8 users, and organized by each participant. We then categorized by themes and features. &#34;&gt;
&lt;img src=&#34;concept_test.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;We conducted concept-testing with 8 users, and organized by each participant. We then categorized by themes and features. &lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;concept_test2.svg&#34; data-caption=&#34;Concept-testing helped us narrow down our scope, and focus on key 3 areas, and specifically 4 feature design recommendations. &#34;&gt;
&lt;img src=&#34;concept_test2.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;Concept-testing helped us narrow down our scope, and focus on key 3 areas, and specifically 4 feature design recommendations. &lt;/b&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;hr /&gt;

&lt;h3 id=&#34;mark-deliver-mark-design-recommendations&#34;&gt;&lt;mark&gt;Deliver&lt;/mark&gt; (Design Recommendations)&lt;/h3&gt;

&lt;p&gt;** &lt;strong&gt;Disclaimer: Below displays only 2 of the total 4 final design recommendations&lt;/strong&gt; **&lt;/p&gt;

&lt;p&gt;In order to ensure that our design solutions stem to delivering the actual user needs, we explicitly stated the user needs that are being met with each design recommendation.&lt;/p&gt;

&lt;h4 id=&#34;1-dashboard-and-data-visualization&#34;&gt;&lt;strong&gt;1. Dashboard and Data Visualization&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Personalized dashboard provides a way to effectively track users&amp;rsquo; past symptoms and even compare and predict how they would feel in the next few days.













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;feature-1.svg&#34; &gt;
&lt;img src=&#34;feature-1.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;feature-1.1.svg&#34; &gt;
&lt;img src=&#34;feature-1.1.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;feature-1.2.svg&#34; &gt;
&lt;img src=&#34;feature-1.2.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;


&lt;h4 id=&#34;2-journal&#34;&gt;&lt;strong&gt;2. Journal&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Journal feature lets users record their symptoms through various means. &lt;strong&gt;Considering accessibility and finger &amp;ldquo;tickling&amp;rdquo; &amp;amp; &amp;ldquo;numbness&amp;rdquo; being a common symptom of cancer, we include voice memo, photo upload, and emotion scale&lt;/strong&gt; to faciliate their input.&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;feature-2.svg&#34; &gt;
&lt;img src=&#34;feature-2.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;feature-2.1.svg&#34; &gt;
&lt;img src=&#34;feature-2.1.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;feature-2.2.svg&#34; &gt;
&lt;img src=&#34;feature-2.2.svg&#34; alt=&#34;&#34; width=&#34;full&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;


&lt;p&gt;To learn more about this project, please reach out to me!&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;reflections&#34;&gt;Reflections&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Interviewing minorities and patients could be overwhelming at first. I thought I needed to know all the jargons related to cancer and oncology treatments. While it would be great to know all these details, acknowledging that you are &amp;ldquo;learning&amp;rdquo; in this space and trying to hear more from interviewees&amp;rsquo; experience not only helps lighten the atmosphere but also gives patients more confidence.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;User centered design approach is critical: For designing data visualizations, more comprehensive data, interaction, and fancy features do not translate to happy experience.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;There are fine lines of products requiring FDA approval, and fortunately, this project did not require it.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Conference Presentations</title>
      <link>https://jinjeon.me/project/conference/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/project/conference/</guid>
      <description>












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jinjeon.me/pdf/cns20.pdf&#34; data-caption=&#34;Click to see in large viewCutler RA, Jeon J, Polyn SM. Characterizing the interaction of temporal and semantic information in categorized memory search. Poster presented at: Cognitive Neuroscience Society; 2020 May 2-5; Virtual&#34;&gt;
&lt;img src=&#34;https://jinjeon.me/pdf/cns20.pdf&#34; alt=&#34;&#34; width=&#34;&amp;#39;max&amp;#39;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;Click to see in large view&lt;/b&gt;&lt;br&gt;Cutler RA, Jeon J, Polyn SM. Characterizing the interaction of temporal and semantic information in categorized memory search. Poster presented at: Cognitive Neuroscience Society; 2020 May 2-5; Virtual
  &lt;/figcaption&gt;


&lt;/figure&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jinjeon.me/pdf/Psychonomics19.pdf&#34; data-caption=&#34;Click to see in large viewCutler RA, Jeon J, Brown-Schmidt S, Polyn SM. Semantic and temporal structure in memory for narratives: A benefit for semantically congruent ideas. Poster presented at: Psychonomic Society; 2019 Nov 14-17; Montreal, QC&#34;&gt;
&lt;img src=&#34;https://jinjeon.me/pdf/Psychonomics19.pdf&#34; alt=&#34;&#34; width=&#34;&amp;#39;max&amp;#39;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;b&gt;Click to see in large view&lt;/b&gt;&lt;br&gt;Cutler RA, Jeon J, Brown-Schmidt S, Polyn SM. Semantic and temporal structure in memory for narratives: A benefit for semantically congruent ideas. Poster presented at: Psychonomic Society; 2019 Nov 14-17; Montreal, QC
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;hr /&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Universal Sentence Encoder and GloVe on Narrative Semantic Representation</title>
      <link>https://jinjeon.me/post/vectorspace/</link>
      <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/post/vectorspace/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;See full repo at &lt;a href=&#34;https://github.com/jeon11/use-glove-narrative.git&#34; target=&#34;_blank&#34;&gt;https://github.com/jeon11/use-glove-narrative.git&lt;/a&gt;&lt;/strong&gt;
&lt;br&gt;
&lt;strong&gt;Note:&lt;/strong&gt; The results are shown in the &lt;a href=&#34;https://jinjeon.me/#posters&#34;&gt;poster&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Google&amp;rsquo;s Universal Sentence Encoder (USE)&lt;/strong&gt; provides 512-dimension vectors for each input that are pre-trained on large corpus, and can be plugged into a variety of different task models, such as sentiment analysis, classification, and etc. It is speed-efficient without losing task accuracy, and also provides embeddings not just for word level, but also for phrases, sentences, and even paragraphs. However, the more the words are given as input, the more likely each word meaning gets diluted.&lt;/p&gt;

&lt;p&gt;This notebook is based on the Semantic Similarity with TF-Hub Universal Encoder tutorial, but uses a separate input from one of the projects. We will also use &lt;strong&gt;GloVe&lt;/strong&gt; vectors to compare how the vectors and cosine similarity differ between the two models.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First, the notebook goes over setting up locally and use one sample data to create embeddings saved out as a separate csv file using Pandas.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Then assuming you have cloned the repository, we call in custom functions to quickly extract vectors of given word, phrase, sentences in USE and GloVe.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;table-of-contents-short-cuts&#34;&gt;Table of Contents/Short-cuts:&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#About-USE-Models-and-Deep-Average-Network&#34;&gt;About USE Models and Deep Average Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Installation-&amp;amp;-Setup&#34;&gt;Installation &amp;amp; Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Path-Setup&#34;&gt;Path Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Raw-Data-Format&#34;&gt;Raw Data Format&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Get-USE-Embeddings&#34;&gt;Get USE Embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Cosine-Similarity&#34;&gt;Cosine Similarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Cosine-Similarity-Example&#34;&gt;Cosine Similarity Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Plotting-Similarity-Matrix&#34;&gt;Plotting Similarity Matrix&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;about-use-models-and-deep-average-network&#34;&gt;About USE Models and Deep Average Network&lt;/h3&gt;

&lt;p&gt;There are two types of models in &lt;strong&gt;USE&lt;/strong&gt;: &lt;strong&gt;Transformer&lt;/strong&gt; and &lt;strong&gt;Deep Averaging Network (DAN)&lt;/strong&gt;. We will use DAN which is a lighter version for efficiency and speed in exchange for reduced accuracy (still accurate enough).&lt;/p&gt;

&lt;p&gt;DAN first averages the input word embeddings to create a sentence embedding. It uses PTB tokenizer, which divides a sentence into a sequence of tokens based on set of rules on  how to process punctuation, articles, etc, in order to create 512 dimension embeddings. This averaged 512 vector is passed to one or more feedforward layers. Then it is multi-task-trained on unsupervised data drawn from various internet sources,  Wikipedia, Stanford Natural Language Inference corpus, web news, and forums.
- Training  goals:
    - Uses skip-thought-like model that predicts the surrounding sentences of a given text (see below)
    - Conversational response suggestion
    - Classification task on supervised data&lt;/p&gt;

&lt;p&gt;The intuition behind deep feedforward neural network is that each layer learns a more abstract representation of the input than the previous one. So its depth allows to capture subtle variations of the input with more depths. Also, each layer only involves a single matrix multiplication, allowing minimal computing time.&lt;/p&gt;

&lt;p&gt;See full USE paper: &lt;a href=&#34;https://arxiv.org/pdf/1803.11175.pdf&#34; target=&#34;_blank&#34;&gt;https://arxiv.org/pdf/1803.11175.pdf&lt;/a&gt;
See full DAN paper: &lt;a href=&#34;https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf&#34; target=&#34;_blank&#34;&gt;https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;installation-setup&#34;&gt;Installation &amp;amp; Setup&lt;/h3&gt;

&lt;p&gt;I used Anaconda to create a TensorFlow-specific environment to customize the package versions. After installing Anaconda&amp;hellip;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Creating a new environment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda create -n py3 python=3.6.8
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Activate the created environment by &lt;code&gt;conda activate py3&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Using pip, install packages for pandas, numpy, seaborn, tensorflow, tensorflow_hub. ie. &lt;code&gt;pip install pckge-name&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Then, let&amp;rsquo;s make sure to set the packages to exact version:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install --upgrade tensorflow=1.15.0
pip install --upgrade tensorflow-hub=0.7.0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once the steps are done, we should be able to run the codes locally.&lt;/p&gt;

&lt;hr /&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from absl import logging
import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
from glob import glob
import re
import seaborn as sns
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;
due to some depecrated methods and changes made with the tf version upgrade from tf1.X to tf2.0, here we use a specific set of Python and tf versions. You can check via &lt;code&gt;pip freeze&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tested on python == 3.6.8 | tensorflow == 1.15.0 | tensorflow_hub == 0.7.0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Or you can check the version in Python via:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import sys
print(sys.version_info)  # sys.version_info(major=3, minor=6, micro=8, releaselevel=&#39;final&#39;)
print(tf.__version__)    # &#39;1.15.0&#39;
print(hub.__version__)   # &#39;0.7.0&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# script variables

# for lite/DAN version:
module_url = &amp;quot;https://tfhub.dev/google/universal-sentence-encoder/2&amp;quot;

# for heavy/Transformer version:
# module_url = &amp;quot;https://tfhub.dev/google/universal-sentence-encoder-large/3&amp;quot;

baseDir = &#39;use-glove-narrative&#39;  # repository/base folder name
embedding_size = 512  # base 512-dimension embedding
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;path-setup&#34;&gt;Path Setup&lt;/h3&gt;

&lt;p&gt;Assuming that you git cloned the project (which is for demo purposes) to your local directory, we set the path so the code knows where to look for certain data files using the &lt;code&gt;baseDir&lt;/code&gt; specified above. We will mainly just work within the cloned folder.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pwd = os.getcwd()
# recursively find absolute path
while os.path.basename(pwd) != baseDir:
    os.chdir(&#39;..&#39;)
    pwd = os.getcwd()
baseDir = pwd
dataDir = baseDir + &#39;/data&#39;

# recursively find all csv files. We will work with one file here
all_csvs = [y for x in os.walk(dataDir) for y in glob(os.path.join(x[0], &#39;*.csv&#39;))]
all_csvs.sort()
all_csvs = all_csvs[0]  # we will just use one sample data
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;raw-data-format&#34;&gt;Raw Data Format&lt;/h3&gt;

&lt;p&gt;To briefly show the data, the data is comprised of numerous idea units, or phrases of words with unique meanings. Here, we are only interested in the &amp;lsquo;text&amp;rsquo; column and &amp;lsquo;index&amp;rsquo; column. We will call in the text of the entire story to create embeddings for each idea unit. Below the example print out, we will loop over each story to create embeddings. Since we will use one story this time, it shouldn&amp;rsquo;t take that long.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# an example print of data format
datafile = pd.read_csv(all_csvs)
datafile.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;paragraph&lt;/th&gt;
      &lt;th&gt;index&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
      &lt;th&gt;scoring&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;One fine day an old Maine man was fishing&lt;/td&gt;
      &lt;td&gt;mentions at least 3 of the following: ‚Äúold‚Äù, ‚Äú...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;on his favorite lake&lt;/td&gt;
      &lt;td&gt;mentions ‚Äúfavorite lake‚Äù or ‚Äúfavorite river‚Äù&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;and catching very little.&lt;/td&gt;
      &lt;td&gt;mentions that he/the fisherman was not having ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Finally, he gave up&lt;/td&gt;
      &lt;td&gt;mentions that he gave up/stopped fishing&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;and walked back along the shore to his fishing...&lt;/td&gt;
      &lt;td&gt;mentions that he walked home/to his fishing sh...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;get-use-embeddings&#34;&gt;Get USE Embeddings&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# let&#39;s read in the data file
textfile = pd.read_csv(all_csvs)
# get the title of the narrative story, cutting out the .csv extension
title = os.path.basename(all_csvs)[:-4]


# create df to save out at the end
vector_df_columns = [&#39;paragraph&#39;, &#39;index&#39;, &#39;text&#39;, &#39;size&#39;]
# create column for each dimension (out of 512)
for i in range(1, embedding_size + 1):
    vector_df_columns.append(&#39;dim&#39; + str(i))
vector_df = pd.DataFrame(columns=vector_df_columns)


# import the Universal Sentence Encoder&#39;s TF Hub module
embed = hub.Module(module_url)  # hub.load(module_url) for tf==2.0.0

# we call in the text column from data file
messages = []
for t in range(0, len(textfile)):
    messages.append(textfile.iloc[t][&#39;text&#39;])

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Reduce logging output.
logging.set_verbosity(logging.ERROR)

with tf.compat.v1.Session() as session:
    session.run([tf.compat.v1.global_variables_initializer(), tf.compat.v1.tables_initializer()])
    message_embeddings = session.run(embed(messages))

# make sure all units are there/sanity check
assert len(message_embeddings) == len(textfile) == len(messages)

# loop over each vector value to corresponding text
for e in range(0, len(message_embeddings)):
    vector_df.at[e, &#39;paragraph&#39;] = textfile.iloc[e][&#39;paragraph&#39;]
    vector_df.at[e, &#39;index&#39;] = textfile.iloc[e][&#39;index&#39;]
    vector_df.at[e, &#39;text&#39;] = messages[e]
    vector_df.at[e, &#39;size&#39;] = len(message_embeddings[e])
    for dim in range(0, len(message_embeddings[e])):
        vector_df.at[e, &#39;dim&#39;+str(dim+1)] = message_embeddings[e][dim]

# display sample format
vector_df.head()

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;paragraph&lt;/th&gt;
      &lt;th&gt;index&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
      &lt;th&gt;size&lt;/th&gt;
      &lt;th&gt;dim1&lt;/th&gt;
      &lt;th&gt;dim2&lt;/th&gt;
      &lt;th&gt;dim3&lt;/th&gt;
      &lt;th&gt;dim4&lt;/th&gt;
      &lt;th&gt;dim5&lt;/th&gt;
      &lt;th&gt;dim6&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;dim503&lt;/th&gt;
      &lt;th&gt;dim504&lt;/th&gt;
      &lt;th&gt;dim505&lt;/th&gt;
      &lt;th&gt;dim506&lt;/th&gt;
      &lt;th&gt;dim507&lt;/th&gt;
      &lt;th&gt;dim508&lt;/th&gt;
      &lt;th&gt;dim509&lt;/th&gt;
      &lt;th&gt;dim510&lt;/th&gt;
      &lt;th&gt;dim511&lt;/th&gt;
      &lt;th&gt;dim512&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;One fine day an old Maine man was fishing&lt;/td&gt;
      &lt;td&gt;512&lt;/td&gt;
      &lt;td&gt;0.0169429&lt;/td&gt;
      &lt;td&gt;-0.0030699&lt;/td&gt;
      &lt;td&gt;-0.0156278&lt;/td&gt;
      &lt;td&gt;-0.00649163&lt;/td&gt;
      &lt;td&gt;0.0213989&lt;/td&gt;
      &lt;td&gt;-0.0541645&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0.0404136&lt;/td&gt;
      &lt;td&gt;-0.0577177&lt;/td&gt;
      &lt;td&gt;0.0108959&lt;/td&gt;
      &lt;td&gt;-0.0337963&lt;/td&gt;
      &lt;td&gt;0.0817816&lt;/td&gt;
      &lt;td&gt;-0.074783&lt;/td&gt;
      &lt;td&gt;0.0231454&lt;/td&gt;
      &lt;td&gt;0.0719041&lt;/td&gt;
      &lt;td&gt;-0.047105&lt;/td&gt;
      &lt;td&gt;0.0127639&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;on his favorite lake&lt;/td&gt;
      &lt;td&gt;512&lt;/td&gt;
      &lt;td&gt;-0.0172151&lt;/td&gt;
      &lt;td&gt;0.0418602&lt;/td&gt;
      &lt;td&gt;0.0105562&lt;/td&gt;
      &lt;td&gt;0.0290091&lt;/td&gt;
      &lt;td&gt;0.0351211&lt;/td&gt;
      &lt;td&gt;-0.0121579&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0.0319399&lt;/td&gt;
      &lt;td&gt;-0.0201722&lt;/td&gt;
      &lt;td&gt;-0.00480706&lt;/td&gt;
      &lt;td&gt;-0.0490393&lt;/td&gt;
      &lt;td&gt;0.0562807&lt;/td&gt;
      &lt;td&gt;-0.0840528&lt;/td&gt;
      &lt;td&gt;0.0359073&lt;/td&gt;
      &lt;td&gt;0.0519214&lt;/td&gt;
      &lt;td&gt;0.0635523&lt;/td&gt;
      &lt;td&gt;-0.0615548&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;and catching very little.&lt;/td&gt;
      &lt;td&gt;512&lt;/td&gt;
      &lt;td&gt;0.0515628&lt;/td&gt;
      &lt;td&gt;0.00556853&lt;/td&gt;
      &lt;td&gt;-0.0606079&lt;/td&gt;
      &lt;td&gt;-0.0281095&lt;/td&gt;
      &lt;td&gt;-0.0631535&lt;/td&gt;
      &lt;td&gt;-0.0586548&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.0266129&lt;/td&gt;
      &lt;td&gt;0.0111167&lt;/td&gt;
      &lt;td&gt;-0.0238963&lt;/td&gt;
      &lt;td&gt;0.00741908&lt;/td&gt;
      &lt;td&gt;-0.0685881&lt;/td&gt;
      &lt;td&gt;-0.0858848&lt;/td&gt;
      &lt;td&gt;0.066858&lt;/td&gt;
      &lt;td&gt;-0.0616563&lt;/td&gt;
      &lt;td&gt;-0.0844253&lt;/td&gt;
      &lt;td&gt;-0.026685&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Finally, he gave up&lt;/td&gt;
      &lt;td&gt;512&lt;/td&gt;
      &lt;td&gt;0.0818241&lt;/td&gt;
      &lt;td&gt;0.00549721&lt;/td&gt;
      &lt;td&gt;-0.0245033&lt;/td&gt;
      &lt;td&gt;0.0286504&lt;/td&gt;
      &lt;td&gt;-0.0284165&lt;/td&gt;
      &lt;td&gt;-0.0575481&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0.0474779&lt;/td&gt;
      &lt;td&gt;-0.00603216&lt;/td&gt;
      &lt;td&gt;-0.0116888&lt;/td&gt;
      &lt;td&gt;-0.06419&lt;/td&gt;
      &lt;td&gt;0.0268704&lt;/td&gt;
      &lt;td&gt;-0.0640136&lt;/td&gt;
      &lt;td&gt;0.103409&lt;/td&gt;
      &lt;td&gt;-0.0235997&lt;/td&gt;
      &lt;td&gt;-0.0781731&lt;/td&gt;
      &lt;td&gt;-0.0365196&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;and walked back along the shore to his fishing...&lt;/td&gt;
      &lt;td&gt;512&lt;/td&gt;
      &lt;td&gt;0.00286058&lt;/td&gt;
      &lt;td&gt;0.0576001&lt;/td&gt;
      &lt;td&gt;0.0103945&lt;/td&gt;
      &lt;td&gt;-0.00301533&lt;/td&gt;
      &lt;td&gt;0.0199591&lt;/td&gt;
      &lt;td&gt;-0.0644398&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.0145959&lt;/td&gt;
      &lt;td&gt;0.0137776&lt;/td&gt;
      &lt;td&gt;0.0165417&lt;/td&gt;
      &lt;td&gt;-0.0406641&lt;/td&gt;
      &lt;td&gt;-0.0204453&lt;/td&gt;
      &lt;td&gt;-0.0713526&lt;/td&gt;
      &lt;td&gt;0.0121754&lt;/td&gt;
      &lt;td&gt;0.00591647&lt;/td&gt;
      &lt;td&gt;0.0262764&lt;/td&gt;
      &lt;td&gt;-0.0329477&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows √ó 516 columns&lt;/p&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(np.shape(vector_df))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(0, 516)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The sample data shows each idea unit/text converted to 512 dimension vectors. &lt;code&gt;np.shape(vector_df)&lt;/code&gt; will return a 41 total idea units/phrases to 516 columns (512 dimensions + custom columns (paragraph info, index, text, and size)). We then use these vectors to explore semantic similarity between text and phrases.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# run the code below to save out as csv file
vector_df.reindex(columns=vector_df_columns)
vector_df.to_csv(title + &#39;_vectors.csv&#39;, index=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;cosine-similarity&#34;&gt;Cosine Similarity&lt;/h2&gt;

&lt;p&gt;As a brief description, &lt;strong&gt;cosine similarity&lt;/strong&gt; is basically the measure of cosine angle between the two vectors. Since we have USE and GloVe vectors that represent words into multidimensional vectors, we can apply these vector values to calculate how similar the two words are.&lt;/p&gt;

&lt;p&gt;It can be easily calculated in Python with its useful packages:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cos_sim = numpy.dot(vector1, vector2)/(numpy.linalg.norm(vector1) * numpy.linalg.norm(vector2))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming we established some basic understanding, let&amp;rsquo;s call in the functions I made so that we can easily get USE and GloVe vectors at multiple word level.&lt;/p&gt;

&lt;p&gt;I will highlight some of the functions below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from get_glove_use import *
help(glove_vec)
help(use_vec)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Help on function glove_vec in module get_glove_use:

glove_vec(item1, item2)
    get vectors for given two words and calculate cosine similarity

    Parameters
    ----------
    item1 : str
        string in glove word pool vector to compare
    item2 : str
        string in glove word pool vector to compare

    Returns
    -------
    item1_vector : array
        item1 GloVe vector
    item2_vector : array
        item2 GloVe vector
    cos_sim : float
        cosine similarity of item1 and item2 vectors

Help on function use_vec in module get_glove_use:

use_vec(item1, item2)
    get USE vectors and cosine similairty of the two items

    Parameters
    ----------
    item1 : str, list
        any word to compare, put in string for more than one word
    item2 : str, list
        any word to compare, put in string for more than one word

    Returns
    -------
    item1_vector : array
        item1 USE vector
    item2_vector : array
        item2 USE vector
    cos_sim : float
        cosine similarity of item1 and item2 vectors
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;cosine-similarity-example&#34;&gt;Cosine Similarity Example&lt;/h3&gt;

&lt;p&gt;Using the two functions above, and another function compare_word_vec (which basically uses the two functions), we can easily obtain cosine similarity of two words.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# using the two functions above, we can get
# GloVe and USE vectors and cosine similarity of two input words
os.chdir(gloveDir)
_, _, glove_sim = glove_vec(&#39;fish&#39;,&#39;bear&#39;)
_, _, use_sim = use_vec(&#39;fish&#39;,&#39;bear&#39;)
print(&#39;use cos: &#39; + str(use_sim))
print(&#39;glove cos: &#39; + str(glove_sim))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


0.11964830574261577
0.5305143
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# the two functions glove_vex and use_vec are use in compare_word_vec
compare_word_vec(&#39;man&#39;,&#39;fish&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


use cos: 0.49838725
glove cos: 0.18601566881803455
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; From the example above, USE and GloVe similarly identy &lt;em&gt;fish&lt;/em&gt; to be somewhat equally similar to &lt;em&gt;bear&lt;/em&gt; and &lt;em&gt;man&lt;/em&gt; (but just in different scale/degree).&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s try comparing at multiple words or phrase level. We will use new functions and give in new inputs as strings.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sentence1 = [&#39;old&#39;, &#39;man&#39;, &#39;caught&#39;, &#39;fish&#39;]
sentence2 = [&#39;bear&#39;, &#39;hunted&#39;, &#39;trout&#39;]
sentence3 = [&#39;bear&#39;,&#39;eat&#39;,&#39;six&#39;,&#39;fish&#39;]

print(&#39;old man caught fish &amp;amp; bear hunted trout:&#39;)
phrase_vec(sentence1, sentence2)

print(&#39;old man caught fish &amp;amp; bear eat six fish:&#39;)
phrase_vec(sentence1, sentence3)

print(&#39;bear hunted trout &amp;amp; bear eat six fish:&#39;)
phrase_vec(sentence2, sentence3)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;old man caught fish &amp;amp; bear hunted trout:
INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


glove sim: 0.36609688461789297
USE sim: 0.50494814
old man caught fish &amp;amp; bear eat six fish:
INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


glove sim: 0.6818474640845398
USE sim: 0.5896743
bear hunted trout &amp;amp; bear eat six fish:
INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


glove sim: 0.6082457470353315
USE sim: 0.72352856
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; From the example above, we can see that USE and GloVe capture somewhat differently. We can see that &lt;em&gt;bear hunted trout&lt;/em&gt; and &lt;em&gt;bear eat six fish&lt;/em&gt; are the most similar to each other, whereas &lt;em&gt;old man caught fish&lt;/em&gt; is also similar to the context of bear eating six fish.&lt;/p&gt;

&lt;p&gt;More detailed analysis is required, but the example above shows great possibilities to exploring semantics.&lt;/p&gt;

&lt;h3 id=&#34;plotting-similarity-matrix&#34;&gt;Plotting Similarity Matrix&lt;/h3&gt;

&lt;p&gt;Now that we can compare similarity of words and sentences, we can plot a simple pairwise matrix, which basically compares how similar each word is to another in the given list. Fortunately, we already have a plot for doing it (using Seaborn).&lt;/p&gt;

&lt;p&gt;I will only use few words as demonstration, since it&amp;rsquo;s been slowing up my computer so much!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plot_sim_matrix([&#39;man&#39;, &#39;bear&#39;, &#39;fish&#39;, &#39;trout&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./use_glove_cosine_similarity_25_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ending-note&#34;&gt;Ending Note&lt;/h2&gt;

&lt;p&gt;In the example above, we only used simple noun words. The stronger blue color, the more similar the two words are. Thus, the diagonal strip is deep blue (similarity of same two words is 1). You can see &lt;em&gt;fish&lt;/em&gt; and &lt;em&gt;trout&lt;/em&gt; are more similar to each other, than is &lt;em&gt;man&lt;/em&gt; to &lt;em&gt;trout&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Keep in mind that you can feed in more words and sentences to create and visualize a larger matrix.&lt;/p&gt;

&lt;p&gt;We looked at setting up USE locally, and creating embeddings from USE. The cloned project also has sample version of GloVe vectors. We use the vectors from the two models to extract vectors and compare similarity of two texts.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
